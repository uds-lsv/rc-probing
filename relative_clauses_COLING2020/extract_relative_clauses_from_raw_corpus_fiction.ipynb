{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/projects/sopro_nmt/badr/conda3/lib/python3.6/site-packages/')\n",
    "\n",
    "import spacy \n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"en_core_web_sm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files = glob.glob(\"COCA_FICTION/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COCA_FICTION/w_fic_2004.txt',\n",
       " 'COCA_FICTION/w_fic_2000.txt',\n",
       " 'COCA_FICTION/w_fic_1997.txt',\n",
       " 'COCA_FICTION/w_fic_2009.txt',\n",
       " 'COCA_FICTION/w_fic_1995.txt',\n",
       " 'COCA_FICTION/w_fic_2012.txt',\n",
       " 'COCA_FICTION/w_fic_2011.txt',\n",
       " 'COCA_FICTION/w_fic_2007.txt',\n",
       " 'COCA_FICTION/w_fic_2010.txt',\n",
       " 'COCA_FICTION/w_fic_1996.txt',\n",
       " 'COCA_FICTION/w_fic_2006.txt',\n",
       " 'COCA_FICTION/w_fic_2001.txt',\n",
       " 'COCA_FICTION/w_fic_1992.txt',\n",
       " 'COCA_FICTION/w_fic_2002.txt',\n",
       " 'COCA_FICTION/w_fic_2005.txt',\n",
       " 'COCA_FICTION/w_fic_1998.txt',\n",
       " 'COCA_FICTION/w_fic_1993.txt',\n",
       " 'COCA_FICTION/w_fic_2008.txt',\n",
       " 'COCA_FICTION/w_fic_1994.txt',\n",
       " 'COCA_FICTION/w_fic_1999.txt',\n",
       " 'COCA_FICTION/w_fic_2003.txt',\n",
       " 'COCA_FICTION/w_fic_1990.txt',\n",
       " 'COCA_FICTION/w_fic_1991.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "relativizer_words = {'who', 'which', 'whose', 'whom', 'which', 'that'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = 10**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_fic_2004\n",
      "Number of collected sentence: 8662\n",
      "w_fic_2000\n",
      "Number of collected sentence: 8375\n",
      "w_fic_1997\n",
      "Number of collected sentence: 7282\n",
      "w_fic_2009\n",
      "Number of collected sentence: 9436\n",
      "w_fic_1995\n",
      "Number of collected sentence: 7413\n",
      "w_fic_2012\n",
      "Number of collected sentence: 5192\n",
      "w_fic_2011\n",
      "Number of collected sentence: 9348\n",
      "w_fic_2007\n",
      "Number of collected sentence: 8412\n",
      "w_fic_2010\n",
      "Number of collected sentence: 8859\n",
      "w_fic_1996\n",
      "Number of collected sentence: 7304\n",
      "w_fic_2006\n",
      "Number of collected sentence: 8908\n",
      "w_fic_2001\n",
      "Number of collected sentence: 8209\n",
      "w_fic_1992\n",
      "Number of collected sentence: 8131\n",
      "w_fic_2002\n",
      "Number of collected sentence: 7768\n",
      "w_fic_2005\n",
      "Number of collected sentence: 8906\n",
      "w_fic_1998\n",
      "Number of collected sentence: 7756\n",
      "w_fic_1993\n",
      "Number of collected sentence: 7562\n",
      "w_fic_2008\n",
      "Number of collected sentence: 9383\n",
      "w_fic_1994\n",
      "Number of collected sentence: 7898\n",
      "w_fic_1999\n",
      "Number of collected sentence: 8482\n",
      "w_fic_2003\n",
      "Number of collected sentence: 8584\n",
      "w_fic_1990\n",
      "Number of collected sentence: 8269\n",
      "w_fic_1991\n",
      "Number of collected sentence: 8509\n"
     ]
    }
   ],
   "source": [
    "sent_idx = 0\n",
    "\n",
    "for _file in text_files:\n",
    "    \n",
    "    _name = _file.split('/')[1][:-4]\n",
    "    \n",
    "    print('Prcoessing: ', _name)\n",
    "    \n",
    "    with open(_file) as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    RC_collection = defaultdict(lambda: defaultdict())\n",
    "    \n",
    "\n",
    "    for seg in range(0, len(text), STEP):\n",
    "        \n",
    "        # use SpaCy module\n",
    "        doc = nlp(text[seg:seg+STEP])\n",
    "        \n",
    "        for (k, sent) in enumerate(doc.sents):\n",
    "\n",
    "            words = [w.text for w in sent]\n",
    "\n",
    "            relativizer_count = len([w for w in words if w in relativizer_words])\n",
    "\n",
    "            # sometimes the corpus is noisy contains tokens @ @ @ @ @ @\n",
    "            if words.count('@') > 2: continue \n",
    "\n",
    "            if relativizer_count != 1: continue\n",
    "\n",
    "            # process sentence with RC token by token\n",
    "            for i in range(len(sent)):\n",
    "\n",
    "                # to avoid unknow errors \n",
    "                try:\n",
    "                    # check if the relativizer word corresponds to a RC\n",
    "                    if sent[i].dep_ == \"relcl\":\n",
    "\n",
    "                        # then the previous word token should be a relativizer for this to RC\n",
    "                        if sent[i-1].text in relativizer_words:\n",
    "\n",
    "                            # THIS IS A RC!\n",
    "                            RC_words = [w.text for w in sent[i].subtree]\n",
    "\n",
    "                            RC_collection[sent_idx]['RC'] = ' '.join(RC_words)\n",
    "                            RC_collection[sent_idx]['RC_subj'] = \\\n",
    "                                [w.text for w in sent[i].subtree if w.dep_ == 'nsubj'][-1]\n",
    "                            RC_collection[sent_idx]['RC_subj_pos'] = \\\n",
    "                                [w.pos_ for w in sent[i].subtree if w.dep_ == 'nsubj'][-1]\n",
    "                            RC_collection[sent_idx]['relativizer_word'] = sent[i-1].text\n",
    "                            RC_collection[sent_idx]['relativizer_func'] = sent[i-1].dep_\n",
    "                            RC_collection[sent_idx]['RC_modifier_head'] = sent[i].head.text\n",
    "                            RC_collection[sent_idx]['RC_modifier_NP'] = ' '.join(w for w in \\\n",
    "                                [t.text for t in sent[i].head.lefts] + [sent[i].head.text])\n",
    "                            RC_collection[sent_idx]['RC_location'] = (i-1, (i-1) + len(RC_words) - 1)\n",
    "                            RC_collection[sent_idx]['RC_context']  = (sent[i-2].text, \\\n",
    "                                sent[i-2 + len(RC_words) + 1].text) \n",
    "                            RC_collection[sent_idx]['sentence'] = sent.text\n",
    "                            \n",
    "                            sent_idx += 1\n",
    "\n",
    "                        # sometimes the distance between relativizer and verb in RC > 1\n",
    "                        elif sent[i-2].text in relativizer_words:\n",
    "                            \n",
    "                            # THIS IS A RC!\n",
    "                            RC_words = [w.text for w in sent[i].subtree]\n",
    "\n",
    "                            RC_collection[sent_idx]['RC'] = ' '.join(RC_words)\n",
    "                            RC_collection[sent_idx]['RC_subj'] = \\\n",
    "                                [w.text for w in sent[i].subtree if w.dep_ == 'nsubj'][-1]\n",
    "                            RC_collection[sent_idx]['RC_subj_pos'] = \\\n",
    "                                [w.pos_ for w in sent[i].subtree if w.dep_ == 'nsubj'][-1]\n",
    "                            RC_collection[sent_idx]['relativizer_word'] = sent[i-2].text\n",
    "                            RC_collection[sent_idx]['relativizer_func'] = sent[i-2].dep_\n",
    "                            RC_collection[sent_idx]['RC_modifier_head'] = sent[i].head.text\n",
    "                            RC_collection[sent_idx]['RC_modifier_NP'] = ' '.join(w for w in \\\n",
    "                                [t.text for t in sent[i].head.lefts] + [sent[i].head.text])\n",
    "\n",
    "                            RC_collection[sent_idx]['RC_location'] = (i-1, (i-1) + len(RC_words) - 1)\n",
    "                            RC_collection[sent_idx]['RC_context']  = (sent[i-3].text, \\\n",
    "                                sent[i-2 + len(RC_words) ].text) \n",
    "                            RC_collection[sent_idx]['sentence'] = sent.text\n",
    "                            \n",
    "                            sent_idx += 1\n",
    "                \n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "    print('Number of collected sentences:', len(RC_collection))\n",
    "\n",
    "    df = pd.DataFrame.from_dict(RC_collection, orient='index')\n",
    "    df.to_csv('RC_FICTION/' + _name + '.RC.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(RC_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
